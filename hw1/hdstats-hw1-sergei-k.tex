\documentclass{article}
\usepackage{fontspec}
\setmainfont{CMU Serif}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}


\newtheorem{problem}{Problem}

\title{HDStats at HSE, 2019. Homework 1.}
\author{Serge K}

\newcommand{\expect}{\operatorname{\mathbb{E}}}

\begin{document}
\maketitle

\begin{problem}
    Prove that
    for any sub-Gaussian real-valued r.v. \( X \).
    variance proxy upperbounds its variance:
    \[
        \operatorname{Var}X \leq \|X\|_{\mathrm{vp}}.
    \]
\end{problem}
\begin{proof}
    Assume, without loss of generality, that \( \expect X = 0\).
    Let \( \sigma^2 \) be the squared variance proxy of \( X \).
    Then \( \log \expect \exp sX \leq \frac12 s^2 \sigma^2 \)
    for all \( s > 0 \).
    \[
        \expect\exp sX \leq \exp \frac12 s^2 \sigma^2,
    \]
    \[
        \expect\left(1 + \frac{s^2}{2} X^2 + O(s^3X^3)\right)
        \leq 1 + \frac{s^2\sigma^2}{2} + O(s^4\sigma^4).
    \]
    Thus for small enough \( s \), including \( s=0 \):
    \[
        \frac{s^2}{2}\operatorname{Var}{X} \leq \frac{s^2\sigma^2}{2} + O(s^3),
    \]
    \[
        \operatorname{Var}{X} \leq \sigma^2 + O(s),
    \]
\end{proof}

\begin{problem}[2.1]
    \( X_1, \ldots, X_n \) be i.i.d. sub-Gaussian r.v.'s with squared variance proxy \( \sigma^2 \).
    Let
    \[
        \hat{m} = \frac1n \sum_{i=1}^n X_i
    \]
    be the standard estimator of \( m = \expect X_1 \).
    Show that for all \( \delta\in(0,1) \)
    holds
    \[
        \mathbb{P}\left(|m - \hat{m}| \geq d\right) \leq \delta,
    \]
    with
    \[
            d= \sqrt{2\sigma^2 n^{-1} \log(2\delta^{-1})}.
    \]
\end{problem}
\begin{proof}
We refer to \textrm{Theorem~1.6} in MIT lectures
which states that if \( X=(X_1, \ldots, X_n) \)
is a vector of i.i.d. sub-Gaussian rv's with
common squared variance proxy \( \sigma^2 \),
then it is a sub-Gaussian rvec with same variance proxy.
Thus \[\begin{split}
 \|\hat{m}\|_{\textrm{vp}}^2
 & = \|\mathbf{1}^\top \frac1n\sum_i X_i\|_{\textrm{vp}}^2 \\
 & = \|\frac1n\sum_i X_i\|_{\textrm{vp}}^2 \\
 & = \frac1n \sigma^2 \end{split}.\]
Now the characterization of this fact is that
\[
\mathbb{P}\left[|\hat{m} - m| > t\right]
\leq \underbrace{\exp(-\frac{nt^2}{2\sigma^2})}_{=\delta}.
\]
Reformulating, for any \( \delta > 0 \) and for
\[ t = \sqrt{
\frac{2}{n\sigma^2}\log\frac{1}{\delta}
} \]
it should hold that
\[ \mathbb{P}[|\hat{m} - m| > t] \leq \delta. \]
\end{proof}

\begin{problem}[2.2]
Let \( X_1, \ldots, X_n \)
be i.i.d. \( 2 \)-integrable rv's
with \( \expect X_1 = m \)
and \( \operatorname{Var}X_1 = \sigma^2 \).
Fix \( \delta\in(0,1) \).
Assume \( (n=kG, k, G)\in \mathbb{N}^3 \),
\( G = 8\log\frac1\delta \).

\[
\overline{X}_g = \frac1k \sum_{i=(g-1)k+1}^{gk} X_i
\]
be the mean of the \( g \)'th group.
\end{problem}
\begin{problem}{2.2a}
Show that \[
\mathbb{P}(\overline{X}_g - m \geq \frac{2\sigma}{\sqrt{k}}) \leq \frac14.
\]
\end{problem}
\begin{proof}
\[\begin{split}
\mathbb{P}\left(|\overline{X}_g - m| \geq \frac{2\sigma}{\sqrt{k}}\right)
&= \mathbb{P}\left((\overline{X}_g - m)^2 \geq \frac{4\sigma^2}{k^2}\right) \\
&\leq k\expect(\overline{X}_g - m)^2\frac{1}{4\sigma^2} = \frac{k\sigma^2}{4k\sigma^2} \\
&= \frac14.
\end{split}\]

\end{proof}

\begin{problem}[2.2b]
Let \( \tilde{m} = \operatorname{Median}(\sum_g \delta_{\overline{X}_g}) \).
Show that
\[
\mathbb{P}\left(\lvert\tilde{m} - m\rvert \geq \frac{2\sigma}{\sqrt{k}}\right)
\leq \mathbb{P}(B \leq \frac{G}{2}),
\]
where \( B\sim\operatorname{Binomial}(G, \frac14) \).
\end{problem}
\begin{proof}
Since \( \tilde{m} = \inf\{x:~\#\{g:~\lvert\overline{X}_g\rvert\geq x\} \geq \frac{G}{2}\} \),
\[\begin{split}
\mathbb{P}\left[|\tilde{m} - m| \geq \frac{2\sigma}{\sqrt{k}} \right]
&= \mathbb{P}\left[
\#\{g:~|\overline{X}_g - m|\geq \frac{2\sigma}{\sqrt{k}}\} \geq \frac{G}{2}
\right]
\\
&= \mathbb{P}\left[
\sum_g I_{[|\overline{X}_g - m|\geq \frac{2\sigma}{\sqrt{k}}]} \geq \frac{G}{2}
\right]
\\
&\leq \mathbb{P}(B\geq \frac{G}{2}).
\end{split}\]
The last inequality holds because
each indicator \( I_{[|\overline{X}_g - m|\geq \frac{2\sigma}{\sqrt{k}}]} \)
is in fact a Bernoulli trial with same success probability \( p\leq\frac14 \),
and thus their sum is distributed as \( \operatorname{Binomial}(G, p) \).
Tails of the latter distribution are bounded by those
of \( B\sim\operatorname{Binomial}(G, \frac14) \).
\end{proof}

\begin{problem}[2.2c]
Show
\[ \mathbb{P}\left[ |\tilde{m} - m|  \geq 4\sigma\sqrt{\frac{2}{n}\log\frac1\delta}\right] \leq \delta. \]
\end{problem}
\begin{proof}
First note that
 \( 4\sigma\sqrt{\frac{2}{n}\log\frac1\delta}
		 = \frac{2\sigma}{\sqrt{k}} \) just as above.
 So it would suffice to prove \( \mathbb{P}(B\geq\frac{G}{2}) \leq \delta \).
 \[\begin{split}
\mathbb{P}(B \geq \frac{G}{2})
&= \mathbb{P}\left(B \geq (1 + 1) \expect{B}\right) \\
&\leq \exp(-\frac13 \expect{B}) = \exp(-\frac{1}{12}G) \\
&= \exp(-\frac{1}{12} 8\log\frac1\delta) \\
&= \exp(\frac23\log\delta) \\
&= \delta^{\frac23}
\end{split}\]
which is greater than \( \delta \) (since \( \delta\in(0,1) \))
but is as good as I could get with Chernoff's bound for tails of Binomial.
\end{proof}

\begin{problem}[3, Subgamma distributions]
\( X_1, \ldots, X_n \)
be independent random variables,
\( a, b \) real numbers, such that
\[
\sum_{i=1}^n \expect|X_i|^k \leq \frac12 k! a^2 b^{k-2}.
\]
Show \( \sum_i X_i \in \operatorname{subg}(a,b) \).
\end{problem}
\begin{proof}
We need to show that for all \( \theta\leq \frac1b \),
\[ \log\expect\exp \theta|\sum_i(X_i - \expect X_i)| \leq \frac{\theta^2 a^2}{2(1-\theta b)}. \]
Now
\[
\log \expect \exp \theta \sum_i (X_i - \expect X_i)
\]
\[\begin{split}
\log\expect \exp \theta \sum_i(X_i - \expect X_i)
&= \log\expect \Pi_i \exp \theta (X_i - \expect X_i) \\
&= \log\Pi_i \expect \exp \theta (X_i - \expect X_i) \\
&= \sum_i \log\expect \exp \theta (X_i - \expect X_i)\\
&= \sum_i \left[\log\expect\exp\theta X_i - \theta \expect X_i\right]\\
&\leq \sum_i \left[\expect \exp \theta X_i - 1 - \theta\expect X_i\right]\\
&= \sum_{k\geq 2} \sum_{i=1}^n \frac{\theta^k \expect X_i^k}{k!} + n - n - \theta \sum_{i=1}^n \expect X_i + \sum_i \theta \expect X_i\\
&\leq \frac12 a^2  \sum_{k\geq2}\theta^{k} b^{k-2}
= \frac12 a^2 \theta^2 \sum_{k\geq 0} \theta^k b^k\\
&= \frac12\theta^2a^2 (\frac{1}{1-\theta b}). \\
\end{split}\]
\end{proof}
\end{document}
